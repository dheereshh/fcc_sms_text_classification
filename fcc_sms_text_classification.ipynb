{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8RZOuS9LWQvv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 22:08:59.296558: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-18 22:08:59.436549: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-18 22:08:59.490603: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-18 22:09:00.069550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-18 22:09:00.069582: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-18 22:09:00.069585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/dheereshantony/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "#try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "#  !pip install tf-nightly\n",
    "#except Exception:\n",
    " # pass\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "#!pip install tensorflow-datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import pad_sequences\n",
    "import nltk\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lMHwYXHXCar3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-18 22:09:01--  https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 2606:4700:20::ac43:4695, 2606:4700:20::681a:321, 2606:4700:20::681a:221, ...\n",
      "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|2606:4700:20::ac43:4695|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 358233 (350K) [text/tab-separated-values]\n",
      "Saving to: ‘train-data.tsv.1’\n",
      "\n",
      "train-data.tsv.1    100%[===================>] 349.84K  1.52MB/s    in 0.2s    \n",
      "\n",
      "2022-10-18 22:09:01 (1.52 MB/s) - ‘train-data.tsv.1’ saved [358233/358233]\n",
      "\n",
      "--2022-10-18 22:09:02--  https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 2606:4700:20::ac43:4695, 2606:4700:20::681a:321, 2606:4700:20::681a:221, ...\n",
      "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|2606:4700:20::ac43:4695|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 118774 (116K) [text/tab-separated-values]\n",
      "Saving to: ‘valid-data.tsv.1’\n",
      "\n",
      "valid-data.tsv.1    100%[===================>] 115.99K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2022-10-18 22:09:02 (3.29 MB/s) - ‘valid-data.tsv.1’ saved [118774/118774]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get data files\n",
    "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
    "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
    "\n",
    "train_file_path = \"train-data.tsv\"\n",
    "test_file_path = \"valid-data.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g_h508FEClxO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ahhhh...just woken up!had a bad dream about u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>you can never do nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>now u sound like manky scouse boy steve,like! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>mum say we wan to go then go... then she can s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>never y lei... i v lazy... got wat? dat day ü ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y                                                  x\n",
       "0  ham  ahhhh...just woken up!had a bad dream about u ...\n",
       "1  ham                           you can never do nothing\n",
       "2  ham  now u sound like manky scouse boy steve,like! ...\n",
       "3  ham  mum say we wan to go then go... then she can s...\n",
       "4  ham  never y lei... i v lazy... got wat? dat day ü ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_file_path, sep=\"\\t\", header=None, names=['y', 'x'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zOMKywn4zReN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>i am in hospital da. . i will return home in e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>not much, just some textin'. how bout you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>i probably won't eat at all today. i think i'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>don‘t give a flying monkeys wot they think and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>who are you seeing?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y                                                  x\n",
       "0  ham  i am in hospital da. . i will return home in e...\n",
       "1  ham         not much, just some textin'. how bout you?\n",
       "2  ham  i probably won't eat at all today. i think i'm...\n",
       "3  ham  don‘t give a flying monkeys wot they think and...\n",
       "4  ham                                who are you seeing?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(test_file_path, sep=\"\\t\", header=None, names=['y', 'x'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train['y'].astype('category').cat.codes\n",
    "y_test  = df_test['y'].astype('category').cat.codes\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_txt = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = WordNetLemmatizer()\n",
    "\n",
    "def clean_txt(txt):\n",
    "    txt = re.sub(r'([^\\s\\w])+', ' ', txt)\n",
    "    txt = \" \".join([l.lemmatize(word) for word in txt.split()\n",
    "                    if not word in stopwords_txt])\n",
    "    txt = txt.lower()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['x'].apply(lambda x: clean_txt(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 500\n",
    "t = Tokenizer(num_words=max_words)\n",
    "t.fit_on_texts(X_train)\n",
    "sequences = t.texts_to_sequences(X_train)\n",
    "sequences_matrix = pad_sequences(sequences, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 500, 50)           50000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                29440     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 22:09:03.311733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 22:09:03.346046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 22:09:03.346140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 22:09:03.346546: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-18 22:09:03.347392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 22:09:03.347473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 22:09:03.347531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 22:09:03.750284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 22:09:03.750547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 22:09:03.750607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 22:09:03.750660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9792 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = tf.keras.layers.Input(shape=[max_len])\n",
    "x = tf.keras.layers.Embedding(max_words, 50, input_length=max_len)(inp)\n",
    "x = tf.keras.layers.LSTM(64)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1, activation='relu')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=x)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='RMSprop',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0718 - accuracy: 0.9913 - val_loss: 0.1354 - val_accuracy: 0.9880\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0740 - accuracy: 0.9838 - val_loss: 0.1185 - val_accuracy: 0.9904\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0537 - accuracy: 0.9934 - val_loss: 0.1018 - val_accuracy: 0.9916\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0469 - accuracy: 0.9952 - val_loss: 0.1315 - val_accuracy: 0.9916\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0500 - accuracy: 0.9952 - val_loss: 0.1191 - val_accuracy: 0.9892\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0528 - accuracy: 0.9955 - val_loss: 0.1320 - val_accuracy: 0.9904\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0488 - accuracy: 0.9964 - val_loss: 0.1228 - val_accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0468 - accuracy: 0.9970 - val_loss: 0.1170 - val_accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0470 - accuracy: 0.9967 - val_loss: 0.1313 - val_accuracy: 0.9904\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0480 - accuracy: 0.9961 - val_loss: 0.1347 - val_accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(sequences_matrix, y_train,\n",
    "              batch_size=128, epochs=10,\n",
    "              validation_split=0.2,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 5ms/step - loss: 0.1499 - accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(X):\n",
    "    x = X.apply(lambda x: clean_txt(x))\n",
    "    x = t.texts_to_sequences(x)\n",
    "    return pad_sequences(x, maxlen=max_len)\n",
    "evall = model.evaluate(preprocessing(df_test['x']), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.150, Accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.3f}, Accuracy: {:.3f}'.format(evall[0], evall[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "J9tD9yACG6M9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "(0.0, 'ham')\n"
     ]
    }
   ],
   "source": [
    "# function to predict messages based on model\n",
    "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
    "def predict_message(pred_text):\n",
    "  p = model.predict(preprocessing(pd.Series([pred_text])))[0]\n",
    "\n",
    "  return (p[0], (\"ham\" if p<0.5 else \"spam\"))\n",
    "\n",
    "pred_text = \"how are you doing today?\"\n",
    "\n",
    "prediction = predict_message(pred_text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Dxotov85SjsC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "You passed the challenge. Great job!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to test your function and model. Do not modify contents.\n",
    "def test_predictions():\n",
    "  test_messages = [\"how are you doing today\",\n",
    "                   \"sale today! to stop texts call 98912460324\",\n",
    "                   \"i dont want to go. can we try it a different day? available sat\",\n",
    "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
    "                   \"you have won £1000 cash! call to claim your prize.\",\n",
    "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
    "                   \"wow, is your arm alright. that happened to me one time too\"\n",
    "                  ]\n",
    "\n",
    "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
    "  passed = True\n",
    "\n",
    "  for msg, ans in zip(test_messages, test_answers):\n",
    "    prediction = predict_message(msg)\n",
    "    if prediction[1] != ans:\n",
    "      passed = False\n",
    "\n",
    "  if passed:\n",
    "    print(\"You passed the challenge. Great job!\")\n",
    "  else:\n",
    "    print(\"You haven't passed yet. Keep trying.\")\n",
    "\n",
    "test_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "fcc_sms_text_classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
